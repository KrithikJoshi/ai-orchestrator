#  AI Orchestrator (DevOps Backend Assignment)

This is a CLI-based AI orchestrator that uses a Large Language Model (LLM) to decide which data processing tasks to run inside Docker containers. The orchestrator receives a natural language prompt, consults an LLM, and runs containerized tasks like `clean_data` and `sentiment_analysis` based on the LLM's plan.

---

## ðŸš€ Features

-  LLM integration via Groq API
-  Task-based container orchestration with Docker
-  Modular containerized microservices
-  CLI interface with Cobra (Go)
-  Data passed between containers via shared volume
-  Outputs final result to both file and terminal

---

##  Project Structure

ai-orchestrator/
â”œâ”€â”€ main.go
â”œâ”€â”€ cmd/
â”‚ â””â”€â”€ run.go
â”œâ”€â”€ internal/
â”‚ â”œâ”€â”€ llm/ # Calls Groq API
â”‚ â””â”€â”€ docker/ # Runs Docker containers
â”œâ”€â”€ tasks/
â”‚ â”œâ”€â”€ clean_data/
â”‚ â”‚ â”œâ”€â”€ clean.py
â”‚ â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”‚ â””â”€â”€ requirements.txt
â”‚ â””â”€â”€ sentiment_analysis/
â”‚ | â”œâ”€â”€ sentiment.py
â”‚ | â”œâ”€â”€ Dockerfile
â”‚ | â””â”€â”€ requirements.txt
| â”œâ”€â”€ data/
| â”‚ â”œâ”€â”€ input.txt # Prompt is saved here
| â”‚ â”œâ”€â”€ output.txt # Cleaned text
â”‚ | â””â”€â”€ sentiment.txt # Final sentiment result
| â”œâ”€â”€ go.mod
| â””â”€â”€ README.md


---

##  Setup Instructions

###  Install Requirements

- [Go](https://go.dev/doc/install)
- [Docker](https://www.docker.com/products/docker-desktop)
- [Groq API Key](https://console.groq.com)

---

###  Step 1: Clone & Build Containers

# Navigate to each task and build
cd tasks/clean_data
docker build -t clean_data .

cd ../sentiment_analysis
docker build -t sentiment_analysis .

###  Step 2: Set Your API Key

# For Bash/Git Bash
export GROQ_API_KEY=your_groq_api_key_here

# For Windows CMD
set GROQ_API_KEY=your_groq_api_key_here

### Step 3: Run the CLI

go run main.go run --prompt "I love the product but hate the shipping."

### Example output

Sending prompt to LLM: I love the product but hate the shipping.
Tasks returned by LLM: [clean_data sentiment_analysis]
Running task in container: clean_data
Running task in container: sentiment_analysis
Final Sentiment Output:
Sentiment: Negative (score: -0.15)

## Architecture

1. User provides CLI prompt

2. Orchestrator calls Groq LLM

3. LLM returns ordered task list

4. Docker containers are spun up in sequence

5. Data passed between containers via volume

6. Final output returned to user